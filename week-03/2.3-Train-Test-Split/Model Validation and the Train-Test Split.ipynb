{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Train-Test Split\n",
    "Week 3 | Lesson 2.3\n",
    "\n",
    "### LEARNING OBJECTIVES\n",
    "*After this lesson, you will be able to:*\n",
    "- Explain the connection between the bias-variance tradeoff and the train-test split\n",
    "- Perform a split of data into testing and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bias-Variance Tradeoff\n",
    "\n",
    "We are seeking a model that generalizes. We will build the model using data that we have, but its value comes in predicting outcomes for data we have not yet seen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's briefly consider the source of possible error in our model:\n",
    "\n",
    "$$E\\left[y_0-\\hat f(x_0)\\right]^2 = \\text{Var}\\left(\\hat f(x_0)\\right) + \\left[\\text{Bias}\\left(\\hat f(x_0)\\right)\\right]^2 + \\text{Var}(\\epsilon)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these represent:\n",
    "\n",
    "- $\\text{Var}\\left(\\hat f(x_0)\\right)$ : the variance in your model; the extent to which your model adjusts to perfectly match your data \n",
    "- $\\left[\\text{Bias}\\left(\\hat f(x_0)\\right)\\right]^2$ : the bias in your model; the extent to which your model is not capable of matching the data \n",
    "- $\\text{Var}(\\epsilon)$ : the variance in the inherent error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THESE ARE ALL POSITIVE\n",
    "\n",
    "We can only hope to minimize them. We have no control over the variance of the inherent error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimize the Bias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimizing the bias is easy. This is actually what we are doing when we doing a least squares regression (OLS).\n",
    "\n",
    "![](assets/ols.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, according to the Gauss-Markov Theorem, \n",
    "\n",
    "> in a linear regression model in which the errors have expectation zero and are uncorrelated and have equal variances, the best linear unbiased estimator (BLUE) of the coefficients is given by the ordinary least squares (OLS) estimator.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Gaussâ€“Markov_theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def make_data(N=30, err=0.8, rseed=1):\n",
    "    # randomly sample the data\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(N, 1) ** 2\n",
    "    y = 10 - 1. / (X.ravel() + 0.1)\n",
    "    if err > 0:\n",
    "        y += err * rng.randn(N)\n",
    "    return X, y\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,6))\n",
    "\n",
    "X, y = make_data()\n",
    "xfit = np.linspace(-0.1, 1.0, 1000)[:, None]\n",
    "\n",
    "models = []\n",
    "for i in range(7):\n",
    "    fig.add_subplot(171+i)\n",
    "    model = PolynomialRegression(4*i+1).fit(X, y)\n",
    "    models.append(model)\n",
    "    plt.scatter(X, y)\n",
    "    plt.plot(xfit, model.predict(xfit))\n",
    "    plt.ylim(-1, 12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = [mean_absolute_error(model.predict(X), y) for model in models]\n",
    "plt.plot(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we pass new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_new, y_new = make_data(rseed=2)\n",
    "\n",
    "error_new = [mean_absolute_error(model.predict(X_new), y_new) for model in models]\n",
    "plt.plot(error)\n",
    "plt.plot(error_new)\n",
    "plt.ylim(-1,25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimize the sum of the Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a much more challenging problem. In essence, we seek a model that is simultaneously lacking in complexity (low variance) and able to fit our known data well (low bias). To do this, we split our data into two sets:\n",
    "\n",
    "- a training set\n",
    "- a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_file_location = '../../../data/boston.csv'\n",
    "boston_housing_df = pd.read_csv(data_file_location, \n",
    "                                index_col=None,\n",
    "                                header=None,\n",
    "                                delim_whitespace=True)\n",
    "\n",
    "boston_housing_df.columns = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \n",
    "                             \"NOX\", \"RM\", \"AGE\", \"DIS\", \n",
    "                             \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \n",
    "                             \"LSTAT\", \"MEDV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boston_housing_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort Parameters by their Correlation with `MEDV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boston_abs_correlations = abs(boston_housing_df.corr()['MEDV'])\n",
    "boston_abs_correlations.sort_values(inplace=True, ascending=False)\n",
    "boston_abs_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just get the Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_names = list(boston_abs_correlations.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't need `MEDV`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_names.pop(0)\n",
    "print(features_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Practices in Developing Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clearly state the problem you wish to solve\n",
    "1. Clearly state the model you will develop to solve the problem\n",
    "1. Clearly state a metric you will use to assess your performance\n",
    "1. Clearly define a benchmark against which you will measure the performance of your model using the metric you selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Median Home Value in Boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/regression_metrics.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    return metrics.mean_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric((1,1,1),(4,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric((1,1,1),(10,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the Train-Test Split\n",
    "\n",
    "The process looks as follows:\n",
    "\n",
    "1. Split the data into two (not necessarily equally sized) sets, the training set and the test set\n",
    "1. Set the test set aside\n",
    "1. Fit the model to the best of our abilities using the training set\n",
    "1. Evaluate the model separately using both the training set and the test set\n",
    "   - the evaluation of the model using the training set can be taken to signify bias\n",
    "   - the evaluation of the model using the test set can be taken to signify variance\n",
    "1. Repeat steps 3 and 4 until an optimal sum of bias and variance is reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "\n",
    "Pull the target vector off of the dataframe.\n",
    "\n",
    "Drop the target vector to prepare the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boston_housing_target = boston_housing_df['MEDV']\n",
    "boston_housing_feature = boston_housing_df.drop('MEDV', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Split the data into a Training Set and a Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix_train, \\\n",
    "feature_matrix_test, \\\n",
    "target_vector_train, \\\n",
    "target_vector_test = train_test_split(boston_housing_feature, \n",
    "                                      boston_housing_target, \n",
    "                                      test_size=0.1,\n",
    "                                      random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Selection\n",
    "\n",
    "We will use forward selection to develop our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's store the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors_training_set = []\n",
    "errors_test_set = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Fit the Model\n",
    "\n",
    "Here we fit a linear model using a single feature, `LSTAT`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(features_names[:1])\n",
    "ftr_mtx_01_p_trn = pd.DataFrame(feature_matrix_train[features_names[:1]])\n",
    "ftr_mtx_01_p_tst = pd.DataFrame(feature_matrix_test[features_names[:1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model with One Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LINEAR_REGRESSOR = LinearRegression()\n",
    "LINEAR_REGRESSOR.fit(ftr_mtx_01_p_trn, target_vector_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_train = LINEAR_REGRESSOR.predict(ftr_mtx_01_p_trn)\n",
    "predict_test = LINEAR_REGRESSOR.predict(ftr_mtx_01_p_tst)\n",
    "error_training_set = metric(predict_train, target_vector_train)\n",
    "error_test_set = metric(predict_test, target_vector_test)\n",
    "errors_training_set.append(error_training_set)\n",
    "errors_test_set.append(error_test_set)\n",
    "error_training_set, error_test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Fit the Model\n",
    "\n",
    "Here we fit a linear model using two features, `LSTAT` and `RM`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(features_names[:2])\n",
    "ftr_mtx_02_p_trn = pd.DataFrame(feature_matrix_train[features_names[:2]])\n",
    "ftr_mtx_02_p_tst = pd.DataFrame(feature_matrix_test[features_names[:2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model with Two Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LINEAR_REGRESSOR = LinearRegression()\n",
    "LINEAR_REGRESSOR.fit(ftr_mtx_02_p_trn, target_vector_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_train = LINEAR_REGRESSOR.predict(ftr_mtx_02_p_trn)\n",
    "predict_test = LINEAR_REGRESSOR.predict(ftr_mtx_02_p_tst)\n",
    "error_training_set = metric(predict_train, target_vector_train)\n",
    "error_test_set = metric(predict_test, target_vector_test)\n",
    "errors_training_set.append(error_training_set)\n",
    "errors_test_set.append(error_test_set)\n",
    "error_training_set, error_test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Fit the Model\n",
    "\n",
    "Here we fit a linear model using three features, `LSTAT`, `RM`, and `PTRATIO`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(features_names[:3])\n",
    "ftr_mtx_03_p_trn = pd.DataFrame(feature_matrix_train[features_names[:3]])\n",
    "ftr_mtx_03_p_tst = pd.DataFrame(feature_matrix_test[features_names[:3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model with Three Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LINEAR_REGRESSOR = LinearRegression()\n",
    "LINEAR_REGRESSOR.fit(ftr_mtx_03_p_trn, target_vector_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_train = LINEAR_REGRESSOR.predict(ftr_mtx_03_p_trn)\n",
    "predict_test = LINEAR_REGRESSOR.predict(ftr_mtx_03_p_tst)\n",
    "error_training_set = metric(predict_train, target_vector_train)\n",
    "error_test_set = metric(predict_test, target_vector_test)\n",
    "errors_training_set.append(error_training_set)\n",
    "errors_test_set.append(error_test_set)\n",
    "error_training_set, error_test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let Python Do The Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_feature_matrics = [\n",
    "    pd.DataFrame(feature_matrix_train[features_names[:4]]),\n",
    "    pd.DataFrame(feature_matrix_train[features_names[:5]]),\n",
    "    pd.DataFrame(feature_matrix_train[features_names[:6]]),\n",
    "    pd.DataFrame(feature_matrix_train[features_names[:7]]),\n",
    "    pd.DataFrame(feature_matrix_train[features_names[:8]]),\n",
    "    pd.DataFrame(feature_matrix_train[features_names[:9]])\n",
    "]\n",
    "\n",
    "test_feature_matrics = [\n",
    "    pd.DataFrame(feature_matrix_test[features_names[:4]]),\n",
    "    pd.DataFrame(feature_matrix_test[features_names[:5]]),\n",
    "    pd.DataFrame(feature_matrix_test[features_names[:6]]),\n",
    "    pd.DataFrame(feature_matrix_test[features_names[:7]]),\n",
    "    pd.DataFrame(feature_matrix_test[features_names[:8]]),\n",
    "    pd.DataFrame(feature_matrix_test[features_names[:9]])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for training_matrix, test_matrix in zip(\n",
    "    training_feature_matrics,\n",
    "    test_feature_matrics):\n",
    "    \n",
    "    LINEAR_REGRESSOR = LinearRegression()\n",
    "    LINEAR_REGRESSOR.fit(training_matrix, target_vector_train)\n",
    "    predict_train = LINEAR_REGRESSOR.predict(training_matrix)\n",
    "    predict_test = LINEAR_REGRESSOR.predict(test_matrix)\n",
    "    error_training_set = metric(predict_train, target_vector_train)\n",
    "    error_test_set = metric(predict_test, target_vector_test)\n",
    "    errors_training_set.append(error_training_set)\n",
    "    errors_test_set.append(error_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(errors_training_set, label='training set')\n",
    "plt.plot(errors_test_set, label='test_set')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
