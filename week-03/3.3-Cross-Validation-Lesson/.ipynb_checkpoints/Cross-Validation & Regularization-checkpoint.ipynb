{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Regularization and Cross-Validation\n",
    "Week 3 | Lesson 2.4\n",
    "\n",
    "### LEARNING OBJECTIVES\n",
    "*After this lesson, you will be able to:*\n",
    "- Explain the connection between the bias-variance tradeoff and the train-test split\n",
    "- Perform a split of data into testing and training sets\n",
    "- Make a prediction on the ISE value using a Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/the_sweet_spot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '../../../lib/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-95010a4f6090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../lib/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '../../../lib/'"
     ]
    }
   ],
   "source": [
    "from os import chdir \n",
    "chdir('../../lib/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named mglearn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7cd09a0dea98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmglearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named mglearn"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X, y = mglearn.datasets.make_wave(n_samples=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "xfit = np.linspace(-3,3,100)\n",
    "plt.scatter(X, y)\n",
    "plt.plot(xfit, xfit*lr.coef_ + lr.intercept_)\n",
    "print(\"lr.coef_: {}\".format(lr.coef_))\n",
    "print(\"lr.intercept_: {}\".format(lr.intercept_))\n",
    "print(\"training set score: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"test set score: {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression on the Boston Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "print(\"training set score: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"test set score: {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, Ridge penalizes the L2 norm of the coefficients, or the Euclidean length of w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From lecture 2.4:\n",
    "\n",
    "> The length of the vector, $\\mathbf v$ is defined as\n",
    "\n",
    "> $$||\\mathbf v||= \\sqrt{\\mathbf v \\cdot \\mathbf v}$$\n",
    "\n",
    "The length of a vector **IS** the L2 norm.\n",
    "\n",
    "$$ \\texttt{norm}_2 = \\sqrt{\\mathbf v \\cdot \\mathbf v} = \\sqrt{v_1^2+v_2^2+\\dots+v_n^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_length = lambda x: np.sqrt(np.dot(x, x))\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector_length((3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm((3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "print(\"training set score: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"test set score: {:.2f}\".format(ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
    "print(\"training set score: {:.2f}\".format(ridge10.score(X_train, y_train)))\n",
    "print(\"test set score: {:.2f}\".format(ridge10.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "print(\"training set score: {:.2f}\".format(ridge01.score(X_train, y_train)))\n",
    "print(\"test set score: {:.2f}\".format(ridge01.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title(\"ridge_coefficients\")\n",
    "plt.plot(ridge.coef_, 's', label=\"Ridge alpha=1\")\n",
    "plt.plot(ridge10.coef_, '^', label=\"Ridge alpha=10\")\n",
    "plt.plot(ridge01.coef_, 'v', label=\"Ridge alpha=0.1\")\n",
    "plt.plot(lr.coef_, 'o', label=\"LinearRegression\")\n",
    "plt.xlabel('Coefficient Index')\n",
    "plt.ylabel('Coefficient Magnitude')\n",
    "plt.ylim(-25, 25)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_ridge_n_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Without enough data standard regression is useless\n",
    "- As more data becomes available, both models improve and standard regression eventually catches up to ridge regression\n",
    "- Ridge regression has a decreased *training* performance -- it is harder for the model to \"memorize the data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, the Lasso penalizes the L1 norm of the coefficients, or sum of the absolute values of the coefficients.\n",
    "\n",
    "$$ \\texttt{norm}_1 = \\rvert v_1 \\rvert+ \\rvert v_2 \\rvert+\\dots+ \\rvert v_n \\rvert = \\sum \\rvert v_i \\rvert$$\n",
    "\n",
    "Because of this many coefficients are exactly zero. This is equivalent to saying that these features are not used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso = Lasso().fit(X_train, y_train)\n",
    "print(\"training set score: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "print(\"test set score: {:.2f}\".format(lasso.score(X_test, y_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso01 = Lasso(alpha=0.01, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"training set score: {:.2f}\".format(lasso01.score(X_train, y_train)))\n",
    "print(\"test set score: {:.2f}\".format(lasso01.score(X_test, y_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso01.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso0001 = Lasso(alpha=0.0001, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"training set score: {:.2f}\".format(lasso0001.score(X_train, y_train)))\n",
    "print(\"test set score: {:.2f}\".format(lasso0001.score(X_test, y_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso0001.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title(\"ridge_coefficients\")\n",
    "plt.plot(lasso.coef_, 's', label=\"Lasso alpha=1\")\n",
    "plt.plot(lasso01.coef_, '^', label=\"Lasso alpha=0.01\")\n",
    "plt.plot(lasso0001.coef_, 'v', label=\"Lasso alpha=0.0001\")\n",
    "\n",
    "plt.xlabel('Coefficient Index')\n",
    "plt.ylabel('Coefficient Magnitude')\n",
    "plt.ylim(-25, 25)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In $\\mathbf K$-**Fold Cross-Validation** rather than splitting the data into a training set and a test set, the data is split $K$ times and $K$ models are developed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We measure then accuracy of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "MSE = make_scorer(mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.load_extended_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_val_scores = cross_val_score(Lasso(), X, y, scoring=MSE)\n",
    "cross_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas = [1E-5, 1E-4, 1E-3, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "for alp in alphas:\n",
    "    RIDGE_REGRESSOR = Ridge(alpha=alp, max_iter=1E5, normalize=True)\n",
    "    cross_val_scores = cross_val_score(RIDGE_REGRESSOR, X, y, scoring=MSE)\n",
    "    mean_mse = np.mean(cross_val_scores)\n",
    "    print(\"Mean MSE for alpha={:6} is {:.2f}\".format(alp, mean_mse))\n",
    "                                             \n",
    "mn_mn_sq_ers = [np.mean(cross_val_score(Lasso(alpha=alp), X, y, scoring=MSE)) for alp in alphas]\n",
    "plt.plot(mn_mn_sq_ers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas = [1E-5, 1E-4, 1E-3, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "for alp in alphas:\n",
    "    LASSO_REGRESSOR = Lasso(alpha=alp, max_iter=1E5, normalize=True)\n",
    "    cross_val_scores = cross_val_score(LASSO_REGRESSOR, X, y, scoring=MSE)\n",
    "    mean_mse = np.mean(cross_val_scores)\n",
    "    print(\"Mean MSE for alpha={:6} is {:.2f}\".format(alp, mean_mse))\n",
    "                                             \n",
    "mn_mn_sq_ers = [np.mean(cross_val_score(Lasso(alpha=alp), X, y, scoring=MSE)) for alp in alphas]\n",
    "plt.plot(mn_mn_sq_ers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ElasticNet \n",
    "\n",
    "The best of both worlds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression with combined L1 and L2 priors as regularizer.\n",
    "\n",
    "Minimizes the objective function, for an $\\alpha$ as a learning rate and $\\gamma$ as an `l1 ratio`:\n",
    "\n",
    "\n",
    "$$\\frac{1}{2n}\\cdot\\texttt{norm}_2(y - Xw)+\\alpha\\gamma\\cdot\\texttt{norm}_1(w)+\\alpha(1-\\gamma)\\cdot\\texttt{norm}_2(w)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elastic_net = ElasticNet().fit(X_train, y_train)\n",
    "print(\"training set score: {:.2f}\".format(elastic_net.score(X_train, y_train)))\n",
    "print(\"test set score: {:.2f}\".format(elastic_net.score(X_test, y_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(elastic_net.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.2).fit(X_train, y_train)\n",
    "print(\"training set score: {:.2f}\".format(elastic_net.score(X_train, y_train)))\n",
    "print(\"test set score: {:.2f}\".format(elastic_net.score(X_test, y_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(elastic_net.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW WE HAVE TWO PARAMETERS TO TUNE!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "An exhaustive search over specified parameter values for an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elastic_net = ElasticNet()\n",
    "parameters = { 'alpha' : [1E-4, 1E-3, 1E-2, 0.1, 1, 10, 100, 1000], 'l1_ratio' : np.linspace(0,1,11)}\n",
    "REGRESSOR = GridSearchCV(elastic_net, parameters, scoring=MSE)\n",
    "REGRESSOR.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search_results = pd.DataFrame(REGRESSOR.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search_results.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search_results['alpha'] = grid_search_results['params'].apply(lambda x: x['alpha'])\n",
    "grid_search_results['l1_ratio'] = grid_search_results['params'].apply(lambda x: x['l1_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search_results.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_results_of_interest = grid_search_results[['mean_test_score', 'mean_train_score', 'alpha', 'l1_ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search_results_of_interest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_test_score(x,y):\n",
    "    index = grid_search_results[(grid_search_results['alpha']==x) & (grid_search_results['l1_ratio'] == y)].index[0]\n",
    "    return grid_search_results.get_value(index, 'mean_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = grid_search_results['alpha'].unique()\n",
    "ys = grid_search_results['l1_ratio'].unique()\n",
    "\n",
    "intensity = [[get_mean_test_score(x, y) for x in xs] for y in ys]\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.pcolormesh(xs, ys, intensity, cmap='RdBu_r')\n",
    "plt.colorbar() #need a colorbar to show the intensity scale"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
