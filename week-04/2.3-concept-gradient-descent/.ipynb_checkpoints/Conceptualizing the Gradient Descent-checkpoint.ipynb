{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descending Into Neural Networks\n",
    "\n",
    "Over the next three weeks, I will be slowly introducing us to the internal mechanics of neural networks. Each week there will be a few lessons leading toward a deeper understanding of this topic. I will try to connect them to other material that we will be studying, but the primary purpose is to gradually learn this very complicated topic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Linear Regression and Conceptualizing the Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare some noisy sample data and plot it\n",
    "\n",
    "We are looking to create a dummy dataset to play with. We want it to be linear but noisy. Our underlying equation is\n",
    "\n",
    "$$f(x) = \\beta_1x+\\beta_0 + \\epsilon$$\n",
    "\n",
    "Where $\\beta_1$ and $\\beta_0$ are set values but $\\epsilon$ is randomly generated noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indep = np.arange(100)\n",
    "\n",
    "# underlying values\n",
    "beta_0 = 3.3\n",
    "beta_1 = 2.3\n",
    "\n",
    "# noise factor \n",
    "gamma = 25 \n",
    "\n",
    "linear_function = lambda x: beta_1*x + beta_0\n",
    "\n",
    "# from a univariate “normal” (Gaussian) distribution of mean 0 and variance 1\n",
    "noise = gamma*np.random.randn(100) \n",
    "\n",
    "noisy_data = linear_function(indep) + noise\n",
    "plt.scatter(indep, noisy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data, it seems pretty clear that there is a linear trend (pretend you don't know that there is). \n",
    "\n",
    "\n",
    "In order to make predictions on new data, we might propose that we use a linear model\n",
    "\n",
    "$$\\hat{f}(x) = \\hat{\\beta}_1x+\\hat{\\beta}_0$$\n",
    "\n",
    "where $\\hat{\\beta}_1$ and $\\hat{\\beta}_0$ represent our estimates of the actual parameters in the underlying linear function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_function = lambda beta_1, beta_0, x: beta_1*x + beta_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this `predict` function to try to fit a model to our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_1 = [prediction_function(2.5,  5, x_i) for x_i in indep]\n",
    "predictions_2 = [prediction_function(3.1,  0, x_i) for x_i in indep]\n",
    "predictions_3 = [prediction_function(1.7, -5, x_i) for x_i in indep]\n",
    "plt.scatter(indep, noisy_data)\n",
    "plt.plot(indep, predictions_1, c='b', label='one')\n",
    "plt.plot(indep, predictions_2, c='r', label='two')\n",
    "plt.plot(indep, predictions_3, c='g', label='three')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Underlying Function\n",
    "\n",
    "Because we know the actual values, we can also measure the error associated with a given $(x_i,y_i)$\n",
    "\n",
    "$$\\text{error}(x_i, y_i) = y_i - \\hat{f}(x_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = lambda beta_1, beta_0, x_i, y_i: y_i - prediction_function(beta_1, beta_0, x_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have\n",
    "\n",
    "1. a prediction function\n",
    "   - $\\hat{f}(x) = \\hat{\\beta}_1x+\\hat{\\beta}_0$\n",
    "   - `prediction_function = lambda beta_1, beta_0, x: beta_1*x + beta_0`\n",
    "1. a weigh to measure the error for a single value in our prediction function\n",
    "   - $\\text{error}(x_i, y_i) = y_i - \\hat{f}(x_i)$\n",
    "   - `error = lambda beta_1, beta_0, x_i, y_i: y_i - prediction_function(beta_1, beta_0, x_i)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing i.e. Finding the Best Prediction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best Prediction Function we will need to know:\n",
    "\n",
    "- the error over our entire data set. \n",
    "    - ignoring the sign of our data\n",
    "    - weighing outliers more heavily\n",
    "\n",
    "We can do this with the sum of the squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_of_squared_errors(beta_hat_1, beta_hat_0, x, y):\n",
    "    errors = [error(beta_hat_1, beta_hat_0, x_i, y_i)\n",
    "              for x_i, y_i in zip(x, y)]\n",
    "    squared_errors = [err**2 for err in errors]\n",
    "    return sum(squared_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sum_of_squared_errors(2.5,  5, indep, noisy_data)\n",
    "print sum_of_squared_errors(3.1,  0, indep, noisy_data)\n",
    "print sum_of_squared_errors(1.7, -5, indep, noisy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a few more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `np.arange`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.arange(2.3,2.4,.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find SSE over two `np.arange`, one for each $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SSEs = []\n",
    "for beta_hat_1, beta_hat_0 in zip(\n",
    "    np.arange(),\n",
    "    np.arange()\n",
    "):\n",
    "    SSE = sum_of_squared_errors(beta_hat_1,\n",
    "                                beta_hat_0, \n",
    "                                indep, \n",
    "                                noisy_data)\n",
    "    print SSE\n",
    "    SSEs.append(SSE)\n",
    "\n",
    "plt.plot(SSEs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the optimal value from the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(np.arange(),np.arange())[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign this to the value `beta_hat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_hat = zip(np.arange(),np.arange())[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = [prediction_function(beta_hat[1], beta_hat[0], x_i) for x_i in indep]\n",
    "plt.scatter(indep, noisy_data)\n",
    "plt.plot(indep, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Wizardy to find the Actual Best Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "X = np.array([indep, np.ones(len(indep))]).T\n",
    "inv(X.T.dot(X)).dot(X.T).dot(noisy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is most likely not what we found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the SSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_of_squared_errors(beta_hat[1], beta_hat[0],\n",
    "                      indep, \n",
    "                      noisy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_of_squared_errors(,\n",
    "                      indep, \n",
    "                      noisy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happened?\n",
    "\n",
    "\n",
    "We clearly have not found the optimal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta_hat_1s = np.arange(2.2,2.4,.01)\n",
    "beta_hat_0s = np.arange(-2,5,.01)\n",
    "SSEs = [[sum_of_squared_errors(beta_hat_1_i, beta_hat_0_i, indep, noisy_data) \n",
    "         for beta_hat_1_i in beta_hat_1s] \n",
    "        for beta_hat_0_i in beta_hat_0s]\n",
    "plt.pcolormesh(beta_hat_1s, beta_hat_0s, SSEs, cmap='YlOrRd')\n",
    "plt.colorbar() #need a colorbar to show the intensity scale\n",
    "plt.title('Sum of Squared Error as a Function of $\\hat\\\\beta$')\n",
    "plt.xlabel('$\\hat{\\\\beta}_1$')\n",
    "plt.ylabel('$\\hat{\\\\beta}_0$')\n",
    "\n",
    "# Plot the path over which we searched for the best\n",
    "plt.plot(np.arange(),np.arange())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WE MISSED IT!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Look at SSE Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "\n",
    "# ax.plot_wireframe(beta_hat_1s, beta_hat_0s, SSEs, rstride=10, cstride=10)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "B_1, B_0 = np.meshgrid(beta_hat_1s, beta_hat_0s)\n",
    "Z = sum_of_squared_errors(B_1, B_0, indep, noisy_data)\n",
    "\n",
    "surf = ax.plot_surface(B_1, B_0, Z, rstride=10, cstride=10, cmap='YlOrRd')\n",
    "ax.view_init(0, 220)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Finding the Optimal Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta_hat_1s = np.arange(2.2,2.4,.01)\n",
    "beta_hat_0s = np.arange(-2,5,.01)\n",
    "SSEs = [[sum_of_squared_errors(beta_hat_1_i, beta_hat_0_i, indep, noisy_data) \n",
    "         for beta_hat_1_i in beta_hat_1s] \n",
    "        for beta_hat_0_i in beta_hat_0s]\n",
    "plt.pcolormesh(beta_hat_1s, beta_hat_0s, SSEs, cmap='YlOrRd')\n",
    "plt.colorbar() #need a colorbar to show the intensity scale\n",
    "plt.title('Sum of Squared Error as a Function of $\\hat\\\\beta$')\n",
    "plt.xlabel('$\\hat{\\\\beta}_1$')\n",
    "plt.ylabel('$\\hat{\\\\beta}_0$')\n",
    "plt.scatter(np.arange(2.2,2.4,.01),np.arange(1,5,.2))\n",
    "plt.plot(2.3, 2, 'x')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
