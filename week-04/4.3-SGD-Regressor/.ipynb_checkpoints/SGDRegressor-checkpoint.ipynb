{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/ml_map.png\" width=\"400px\">\n",
    "\n",
    "[source](http://scikit-learn.org/stable/tutorial/machine_learning_map/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/regression_ml_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Stochastic Gradient Descent? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the `sklearn` documentation:\n",
    "\n",
    "> The advantages of Stochastic Gradient Descent are:\n",
    "> - Efficiency.\n",
    "> - Ease of implementation (lots of opportunities for code tuning).\n",
    "\n",
    "> The disadvantages of Stochastic Gradient Descent include:\n",
    "> - SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n",
    "> - SGD is sensitive to feature scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stated even more plainly:\n",
    "\n",
    "> [`SGDRegressor`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor) is well suited for regression problems with a large number of training samples (> 10.000), for other problems we recommend [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge), [`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso), or [`ElasticNet`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/100K.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of the Box Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import chdir; chdir('../../../lib/')\n",
    "from mglearn.datasets import load_extended_boston\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain and Dataset\n",
    "\n",
    "We are interested in comparing the performance of the standard `sklearn` linear regressors out of the box. As such, our \"dataset\" is the set of the following four linear regressors:\n",
    "\n",
    "- `sklearn.linear_model.LinearRegression`\n",
    "- `sklearn.linear_model.Ridge`\n",
    "- `sklearn.linear_model.Lasso`\n",
    "- `sklearn.linear_model.SGDRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform the regression we will be using the \"extended boston\" dataset provided by the `mglearn` library. This library has 506 instances and 104 features. It is accompanied by a numeric target vector of quantitative values. It is a \"canonical\" linear regression dataset and is often used for learning linear regression concepts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = load_extended_boston()\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: It is considered a best practice when using Stochastic Gradient Descent (and linear models in general) to scale onese data. We will be preprocessing our data using the `StandardScaler` included with `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Given the set of four linear regressors in their \"out-of-the-box\" state i.e. default, with no tuning parameters applied, we wish to see how these perform when applied to the same dataset. \n",
    "\n",
    "### Solution Statement\n",
    "\n",
    "As this is an exploratory problem, our solution will take the form of scores for each model presented in a plot. \n",
    "\n",
    "### Metric\n",
    "\n",
    "N/A\n",
    "\n",
    "### Benchmark\n",
    "\n",
    "N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "print LR.score(X_train, y_train)\n",
    "print LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_and_score_linear_model(model, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    return {'model': model, 'train_score' : model.score(X_train, y_train), 'test_score': model.score(X_test, y_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit_and_score_linear_model(LinearRegression(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit_and_score_linear_model(Ridge(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit_and_score_linear_model(Lasso(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit_and_score_linear_model(SGDRegressor(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fits = [fit_and_score_linear_model(LinearRegression(), X, y),\n",
    "        fit_and_score_linear_model(Ridge(), X, y),\n",
    "        fit_and_score_linear_model(Lasso(), X, y),\n",
    "        fit_and_score_linear_model(SGDRegressor(), X, y)]\n",
    "\n",
    "fits = pd.DataFrame(fits)\n",
    "fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Munging to make Seaborn Happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for_plot = pd.concat([fits[['model','test_score']],fits[['model','train_score']]])\n",
    "for_plot['model'] = for_plot['model'].astype(str).str.extract('(.+)\\(', expand=False)\n",
    "for_plot['type'] = ['test']*4+['train']*4\n",
    "for_plot['train_score'].fillna(for_plot['test_score'], inplace=True)\n",
    "for_plot.drop('test_score', inplace=True, axis=1)\n",
    "for_plot.columns = ['model', 'score', 'type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barplot = sns.barplot(x='model', y='score', hue='type', data=for_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain and Dataset\n",
    "\n",
    "We are interested in comparing the timing performance of three standard `sklearn` linear regressors out of the box using datasets of different sizes. As such, our \"dataset\" is the set of the following three linear regressors:\n",
    "\n",
    "- `sklearn.linear_model.LinearRegression`\n",
    "- `sklearn.linear_model.Ridge`\n",
    "- `sklearn.linear_model.SGDRegressor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform the regression we will be using the `make_regression` function built into provided by the `sklearn.datasets` library. This functions constructs a regression problem with a given number of instances and a given number of features features. It is accompanied by a numeric target vector of quantitative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn import datasets\n",
    "X, y = datasets.make_regression(int(1e4), \n",
    "                                n_features=1000, \n",
    "                                noise=50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: It is considered a best practice when using Stochastic Gradient Descent (and linear models in general) to scale onese data. We will be preprocessing our data using the `StandardScaler` included with `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Given the set of three linear regressors in their \"out-of-the-box\" state i.e. default, with no tuning parameters applied, we wish to see how these perform when applied to the regression datasets of varying sizes. \n",
    "\n",
    "### Solution Statement\n",
    "\n",
    "As this is an exploratory problem, our solution will take the form of scores for each model presented in a plot. \n",
    "\n",
    "### Metric\n",
    "\n",
    "N/A\n",
    "\n",
    "### Benchmark\n",
    "\n",
    "N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "fit = fit_and_score_linear_model(LinearRegression(), X, y)\n",
    "end = time()\n",
    "fit['test_score'], end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_train_score_for_LM_of_size_n(model, n):\n",
    "    X, y = datasets.make_regression(int(n),\n",
    "                                    n_features=1000, \n",
    "                                    noise=50.0)\n",
    "    start = time()\n",
    "    fit = fit_and_score_linear_model(model, X, y)\n",
    "    end = time()\n",
    "    return {'score': fit['test_score'], 'time': end - start}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for n in [1e2, 1e3, 1e4]:\n",
    "    res_dict = time_train_score_for_LM_of_size_n(LinearRegression(), n)\n",
    "    res_dict['type'] = 'LR'\n",
    "    res_dict['n'] = n\n",
    "    results.append(res_dict)\n",
    "    \n",
    "    res_dict = time_train_score_for_LM_of_size_n(SGDRegressor(), n)\n",
    "    res_dict['type'] = 'SGD'\n",
    "    res_dict['n'] = n\n",
    "    results.append(res_dict)\n",
    "    \n",
    "    res_dict = time_train_score_for_LM_of_size_n(Ridge(), n)\n",
    "    res_dict['type'] = 'Ridge'\n",
    "    res_dict['n'] = n\n",
    "    results.append(res_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "sns.barplot(x='n', y='time', hue='type', data=results_df)\n",
    "plt.yscale('log')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Our Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain and Dataset\n",
    "\n",
    "We are interested in comparing the performance of two standard `sklearn` linear regressors after they have been tuned. As such, our \"dataset\" is the set of the following two linear regressors:\n",
    "\n",
    "- `sklearn.linear_model.Ridge`\n",
    "- `sklearn.linear_model.SGDRegressor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform the regression we will be using the `make_regression` function built into provided by the `sklearn.datasets` library. This functions constructs a regression problem with a given number of instances and a given number of features features. It is accompanied by a numeric target vector of quantitative values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use it to construct a regression problem with 1000000 instances and 1000 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn import datasets\n",
    "X, y = datasets.make_regression(int(1e5), \n",
    "                                n_features=1000, \n",
    "                                noise=75.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: It is considered a best practice when using Stochastic Gradient Descent (and linear models in general) to scale onese data. We will be preprocessing our data using the `StandardScaler` included with `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Given the set of two linear regressors, we wish to see how these perform when tuned for performance against a large dataset. \n",
    "\n",
    "### Solution Statement\n",
    "\n",
    "As this is an exploratory problem, our solution will take the form of scores for each model presented in a plot. \n",
    "\n",
    "### Metric\n",
    "\n",
    "We will use the default regression scorer, the $R^2$ and its performance against the test set. We will also be looking at time. \n",
    "\n",
    "### Benchmark\n",
    "\n",
    "We will use the performance of the default `Ridge` regression as our benchmark performance and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "fit = fit_and_score_linear_model(Ridge(), X, y)\n",
    "end = time()\n",
    "print end-start, fit['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a benchmark time of 9.986 seconds and a benchmark $R^2$ score of $0.886262$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the Ridge Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge_results = []\n",
    "alphas = [0.001, 0.01, 0.1, 1.0, 2, 5, 10]\n",
    "for alpha in alphas:\n",
    "    print alpha\n",
    "    start = time()\n",
    "    fit = fit_and_score_linear_model(Ridge(alpha=alpha), X, y)\n",
    "    end = time()\n",
    "    results.append({'alpha': alpha,\n",
    "                    'type' : 'ridge', \n",
    "                   'score' : fit['test_score'],\n",
    "                   'time' : end-start})\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge_results_df = pd.DataFrame(ridge_results)\n",
    "ridge_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge_results_df = pd.DataFrame(results)\n",
    "plt.plot(ridge_results_df['alpha'],\n",
    "         ridge_results_df['score'])\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd_results = []\n",
    "alphas = [0.001, 0.01, 0.1, 1.0, 2, 5, 10]\n",
    "for alpha in alphas:\n",
    "    print alpha\n",
    "    start = time()\n",
    "    fit = fit_and_score_linear_model(\n",
    "                SGDRegressor(alpha=alpha), X, y)\n",
    "    end = time()\n",
    "    sgd_results.append({'alpha': alpha,\n",
    "                        'type' : 'SGD', \n",
    "                        'score' : fit['test_score'],\n",
    "                        'time' : end-start})\n",
    "    \n",
    "sgd_results_df = pd.DataFrame(sgd_results)\n",
    "sgd_results_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(sgd_results_df['alpha'],\n",
    "         sgd_results_df['score'])\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd_results_2 = []\n",
    "\n",
    "fit = fit_and_score_linear_model(\n",
    "                    SGDRegressor(alpha=.001,\n",
    "                                 warm_start=True), X, y)\n",
    "sgd_results_2.append({'alpha': alpha,\n",
    "                    'type' : 'SGD', \n",
    "                    'score' : fit['test_score'],\n",
    "                    'time' : end-start})\n",
    "\n",
    "\n",
    "for _ in range(25):\n",
    "    fit = fit_and_score_linear_model(fit['model'], X, y)\n",
    "    \n",
    "    sgd_results_2.append({'alpha': alpha,\n",
    "                        'type' : 'SGD', \n",
    "                        'score' : fit['test_score'],\n",
    "                        'time' : end-start})\n",
    "    \n",
    "sgd_results_2_df = pd.DataFrame(sgd_results_2)\n",
    "sgd_results_2_df       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(sgd_results_2_df['score'])),\n",
    "         sgd_results_2_df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
