{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "---\n",
    "title: Intro Classification + KNN\n",
    "duration: \"1:5\"\n",
    "creator:\n",
    "    name: Kiefer Katovich + David Yerrington\n",
    "    city: SF\n",
    "    updated by: John Marin\n",
    "    city: LA\n",
    "---\n",
    "```\n",
    "\n",
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Intro to Classification + KNN\n",
    "Week 5 | Lesson 1.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification is the prediction of a <u>qualitative</u> response for an observation (unlike regression where we assume the response variable is quantitative).\n",
    "\n",
    "- <b> Predicting a qualitative response for an observation can be referred to as classifying that observation, since it involves assigning the observation to a category, or class. <br> <br>\n",
    "\n",
    "- It is also the case that the methods used for classification first predict the probability of each of the categories of a qualitative variable, as the basis for making the classi- fication. In this sense they also behave like regression methods </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEARNING OBJECTIVES\n",
    "*After this lesson, you will be able to:*\n",
    "- Identify classification problems\n",
    "- Understand the difference between regression and classification problems\n",
    "- Understand the basic difference between KNN and Logistic Regression\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5 mins) Discussion:\n",
    "\n",
    "# 1.  Exactly what is classification and how is it different than regression?\n",
    "# 2 . What sort of problems do you solve with classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Identify that problem:  Classification or Regression?\n",
    "<br>\n",
    "<img src=\"https://snag.gy/0j5DbL.jpg\" width=500> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify that problem: Classification or Regression? \n",
    "<br>\n",
    "\n",
    "<img src=\"https://snag.gy/Rk6sEw.jpg\" width=500> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify that problem: Classification or Regression?\n",
    "<br>\n",
    "\n",
    "<img src=\"https://snag.gy/lS3FNa.jpg\" width=520> \n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# Common Classification Methods\n",
    "\n",
    "## K-Nearest Neighbors\n",
    "![](https://snag.gy/J38wxN.jpg)\n",
    "\n",
    "## Logistic Regression\n",
    "![](https://snag.gy/NCnh3b.jpg)\n",
    "\n",
    "## Naive Bayes\n",
    "![](https://snag.gy/ZJwmn6.jpg)\n",
    "\n",
    "## Decision Trees\n",
    "![](https://snag.gy/cJL5gr.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Intro\n",
    "\n",
    "![](https://snag.gy/0Jns5x.jpg)\n",
    "\n",
    "Classification methods in machine learning are fundamentally supervised methods where the training data which observations are associated with a (discrete) label designating their class.  Classification is different than regression (with continious values) because we are now predicting classes / labels.  This can be thought of as a discrimination problem, modelling the differences or similarities between groups. \n",
    "\n",
    "*Classification is supervised because we know the labels of our trained / sampled observations.*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Evaluation\n",
    "\n",
    "Classification is assessed much differently than continuious regression.  Generally, we are concerned with if we misidentified anything incorrectly, completely missed the mark, or predicted correctly between our traning and test sets during cross validation.  There are a few different things we usually talk about and look at when it pertains to classification related to these ideas such as **precision**, **recall**, **accuracy**, **F-measures**, **class imbalance**, and our beloved **Reciever Operator Curve**.\n",
    "\n",
    "Once we get a sense of how our classfication method performs, we have the opporutnity to tune for sensitivity or specificity.\n",
    "\n",
    "> **Sensitivity and specificity** are statistical measures of the performance of a binary classification test, also known in statistics as classification function:\n",
    "\n",
    "> **Sensitivity** (also called the true positive rate, the recall, or probability of detection[1] in some fields) measures the proportion of positives that are correctly identified as such (e.g., the percentage of sick people who are correctly identified as having the condition).\n",
    "\n",
    "> **Specificity** (also called the true negative rate) measures the proportion of negatives that are correctly identified as such (e.g., the percentage of healthy people who are correctly identified as not having the condition).\n",
    "\n",
    "> [Sensitivity and Specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)\n",
    "\n",
    "\n",
    "## Contingency Table / Confusion Matrix\n",
    "<img src=\"https://snag.gy/qit9l3.jpg\" width=520> \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Confusion Matrix - sklearn**\n",
    "<img src=\"https://snag.gy/b6VDIo.jpg\" width=500>\n",
    "<br>\n",
    "\n",
    "## ROC Curve Analysis\n",
    "<img src=\"https://snag.gy/CBxZbh.jpg\" width=500>\n",
    "\n",
    "## sklearn \"classification_report()\"\n",
    "```python\n",
    ">>> from sklearn.metrics import classification_report\n",
    ">>> y_true = [0, 1, 2, 2, 0]\n",
    ">>> y_pred = [0, 0, 2, 1, 0]\n",
    ">>> target_names = ['class 0', 'class 1', 'class 2']\n",
    ">>> print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "    class 0       0.67      1.00      0.80         2\n",
    "    class 1       0.00      0.00      0.00         1\n",
    "    class 2       1.00      0.50      0.67         2\n",
    "\n",
    "avg / total       0.67      0.60      0.59         5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors classification walkthrough\n",
    "\n",
    "From here on out we are going to look at how the kNN algorithm classifies malignant vs. benign tumor category in the Wisconsin breast cancer dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## kNN\n",
    "\n",
    "### What is k-Nearest Neighbors?\n",
    "\n",
    "- When a prediction is required for an unseen (out-of-sample) data instance, the kNN algorithm will search through the training dataset and localize the k-most similar instances. The attributes of the most similar instances are summarized and returned (i.e. \"voted upon\") and become the prediction value of the unseen instance. <br><br>\n",
    "\n",
    "- The similarity measure depends on the data involved. The Euclidean distance is often used, but categorical or binary data lend themselves to the Hamming distance. <br><br>\n",
    "\n",
    "- For regression problems, the average of the neighbors may be returned, whereas for classification problems, the most prevalent class is returned. <br><br>\n",
    "\n",
    "![](https://snag.gy/hatSE6.jpg)\n",
    "\n",
    "The pseudocode algorithm for kNN is as follows:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "for unclassified_point in sample:\n",
    "    for known_point in known_class_points:\n",
    "        calculate distances (euclidean or other) between known_point and unclassified_point\n",
    "    for k in range of specified_neighbors_number:\n",
    "        find k_nearest_points in known_class_points to unclassified_point\n",
    "    assign class to unclassified_point using \"votes\" from k_nearest_points\n",
    "```\n",
    "> ### Common KNN Distance Functions\n",
    "> These distance functions can be used with KNN.  Euclidean is the most common choice.\n",
    ">\n",
    "> ### Euclidean  \n",
    "> $\\sqrt{\\sum\\limits_{i=1}^k(x_i - y_i)^2}$\n",
    ">\n",
    "> ### Manattan \n",
    "> $\\sum\\limits_{i=1}^k \\left| x_i - y_i \\right|$\n",
    ">\n",
    "> ### Minkowski\n",
    "> $\\left(\\sum_{i=1}^n |x_i-y_i|^p\\right)^{1/p}$\n",
    "\n",
    "---\n",
    "\n",
    "[NOTE: in the case of ties, sklearn's `KNeighborsClassifier()` will just choose the first class using uniform weights! If this is unappealing to you you can change the weights keyword argument to 'distance'.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
