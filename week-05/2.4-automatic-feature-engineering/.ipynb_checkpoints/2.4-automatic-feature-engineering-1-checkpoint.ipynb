{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Automatic Feature Engineering, Pt. 1\n",
    "Week 5 | Lesson 2.4\n",
    "\n",
    "### LEARNING OBJECTIVES\n",
    "*After this lesson, you will be able to:*\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import chdir; chdir('../lib')\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from madelon import standard_classification, load_madelon_set_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Domain & Data\n",
    "\n",
    "### Domain\n",
    "\n",
    "Prepared for the Neural Information Processing Symposium 2003 Feature Extraction Workshop\n",
    "\n",
    "http://clopinet.com/isabelle/Projects/NIPS2003\n",
    "\n",
    "### Data \n",
    "\n",
    "MADELON is an artificial dataset, which was part of the NIPS 2003 feature selection challenge. This is a two-class classification problem with continuous input variables. The difficulty is that the problem is multivariate and highly non-linear.\n",
    "\n",
    "MADELON is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features one must separate the examples into the 2 classes (corresponding to the +-1 labels). We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "madelon_feature_df, madelon_target_df = load_madelon_set_into_df()\n",
    "madelon_feature_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "madelon_feature_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "The NIPS 2003 challenge in feature selection is to find feature selection algorithms that significantly outperform methods using all features in performing a binary classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Statement\n",
    "\n",
    "We will develop a binary classification model and attempt to augment its performance using automatic feature selection techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "trained_knn = standard_classification(KNeighborsClassifier,\n",
    "                                      madelon_feature_df,\n",
    "                                      madelon_target_df,\n",
    "                                      {'n_neighbors' : 17,\n",
    "                                       'n_jobs':-1},\n",
    "                                      random_state_split=42)\n",
    "\n",
    "trained_logreg = standard_classification(LogisticRegression,\n",
    "                                         madelon_feature_df,\n",
    "                                         madelon_target_df,\n",
    "                                         {'random_state' : 17,\n",
    "                                          'n_jobs':-1},\n",
    "                                         random_state_split=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric \n",
    "\n",
    "Today, we will examine all of the metrics that we have used so far - Accuracy, Precision, Recall, and F1-Score, as well as look at a Confusion Matrix. For comparing models, we will use Accuracy.\n",
    "\n",
    "## Benchmark\n",
    "\n",
    "We will use as a benchmark our mean accuracy across five random train test splits using a K Nearest Neighbors model with an optimal value for number of `n_neighbors`. This model had a 73.8% accuracy.\n",
    "\n",
    "<img src=\"assets/benchmark.png\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`Pipeline`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) can be used to chain multiple estimatros into one.\n",
    "\n",
    "We will use it as our primary tool for creating automated feature engineering flows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages\n",
    "\n",
    "1. It is a **convenience method** allowing us to call `fit`, `predict`, and `score` only once in order to build and validate a model.\n",
    "1. It allows for joint parameter selection, allowing use to **grid search over all parameters** in the pipeline at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import samples_generator\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, \\\n",
    "X_test,  \\\n",
    "y_train, \\\n",
    "    y_test = train_test_split(madelon_feature_df, \n",
    "                              madelon_target_df,\n",
    "                              random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "this_pipeline = (SelectKBest(f_classif, k=5),\n",
    "                 KNeighborsClassifier(n_neighbors=17))\n",
    "anova_classifier = make_pipeline(*this_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anova_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anova_classifier.score(X_train, y_train), \\\n",
    "    anova_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How did it do against our benchmark?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete this wrapper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def general_classifier(X, y, model, random_state):\n",
    "    \n",
    "    # TODO: 2. Split the data into training and testing sets\n",
    "        \n",
    "    # TODO: 3. create new model\n",
    "    \n",
    "    # TODO: 4. fit the model\n",
    "\n",
    "    # TODO: 5. score the model\n",
    "\n",
    "    return {'classifier' : classifier,\n",
    "            'train_score' : train_score,\n",
    "            'test_score' : test_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your Function\n",
    "\n",
    "You should have the same scores as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "this_pipeline = (\n",
    "    SelectKBest(f_classif, k=5),\n",
    "    KNeighborsClassifier(n_neighbors=17)\n",
    ")\n",
    "general_classifier(madelon_feature_df,\n",
    "                   madelon_target_df,\n",
    "                   make_pipeline(*this_pipeline), 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Pipeline` and `make_pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `make_pipeline` method is a helper function that helps with constructing a `Pipeline` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = [('selectkbest', SelectKBest(f_classif, k=5)),\n",
    "              ('classifier', KNeighborsClassifier(n_neighbors=17))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(estimators)\n",
    "via_make = make_pipeline(*this_pipeline)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "via_make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can not compare them via equality because they are objects and not **the same** object, but looking at their attributes, you can see that they are equivalent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Steps in a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('As a List')\n",
    "[print(step) for step in pipe.steps]\n",
    "\n",
    "print('\\nIndexed as a List')\n",
    "print(pipe.steps[0])\n",
    "\n",
    "print('\\nAs a Dictionary')\n",
    "print(pipe.named_steps['selectkbest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting Params after Instantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses a common syntax that you will see in a lot of query languages.\n",
    "\n",
    "The syntax is \n",
    "\n",
    "    named_estimator__parameter\n",
    "    \n",
    "Python loves those dunders!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe.set_params(classifier__n_jobs=-1)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline and GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick review of [`GridSearchCV`](http://scikit-learn.org/stable/modules/grid_search.html#grid-search).\n",
    "\n",
    "**Hyper-parameters** are parameters that are not directly learnt within estimators.\n",
    "\n",
    "In scikit-learn they are passed as arguments to the constructor of the estimator classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search provided by `GridSearchCV` exhaustively generates candidates from a grid of parameter values specified with the param_grid parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = dict(selectkbest__k=range(5,15),\n",
    "              classifier__p=[1,2])\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This specificies that the following grid should be explored:\n",
    "\n",
    "- across `p` values for `KNearestNeighborsClassifer` (which specifies the way distance is calculated)\n",
    "- across `k`values for `SelectKBest` (which specifies the number of features to use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's search over our `madelon` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_grid_search = GridSearchCV(pipe, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search_results = general_classifier(madelon_feature_df,\n",
    "                                         madelon_target_df,\n",
    "                                         pipe_grid_search,\n",
    "                                         42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search_results['train_score'], grid_search_results['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How did it do against our benchmark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search_results['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_search_results['classifier'].cv_results_)\n",
    "results_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,4))\n",
    "\n",
    "fig.add_subplot(121)\n",
    "sns.stripplot(y='mean_train_score',\n",
    "              x='param_selectkbest__k',\n",
    "              hue='param_classifier__p',\n",
    "              data=results_df)\n",
    "plt.ylim(0.6,1)\n",
    "\n",
    "fig.add_subplot(122)\n",
    "sns.stripplot(y='mean_test_score',\n",
    "              x='param_selectkbest__k',\n",
    "              hue='param_classifier__p',\n",
    "              data=results_df)\n",
    "plt.ylim(0.6,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Feature Selection\n",
    "\n",
    "## Why Feature Selection? \n",
    "\n",
    "Performing feature selection on our data can provide several major benefits to the development of our models. Feature selection can help with:\n",
    "\n",
    "1. *Prediction Accuracy*, especially in terms of preventing overfitting. \n",
    "\n",
    "   - especially true when the number of instances is comparable or even smaller than the number of features\n",
    "\n",
    "1. *Model Interpretability*, removing unneccessary features creates a model that is easier to understand, explain, and use\n",
    "\n",
    "   - note that deep learning explicitly rejects this notion, actually creating hidden features that are not intended for human consumption\n",
    "   \n",
    "1. *Reduction in Complexity*, especially in terms of time and space complexity\n",
    "\n",
    "   - a smaller model requires a smaller dataset (think columns not rows)\n",
    "   - a smaller model requires less computation time\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Feature Selection in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adding new features, or with high-dimensional datasets in general, it can be a good idea to reduce the number of features to only the most useful ones, and discard the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can lead to simpler models that generalize better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how can you know how good each feature is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `sklearn`, there are three basic strategies:\n",
    "\n",
    "1. univariate statistics\n",
    "   - ANOVA\n",
    "1. model-based selection\n",
    "1. iterative selection\n",
    "   - forward-, backward-, and other kinds of selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection via Univariate Statistics\n",
    "\n",
    "In univariate statistics, we compute whether there is a statistically significant relation‐ ship between each feature and the target.\n",
    "\n",
    "In the case of classification, this is also known as analysis of variance (ANOVA).\n",
    "\n",
    "A key property of these tests is that they are univari‐ ate, meaning that they only consider each feature individually.\n",
    "\n",
    "Consequently, a feature will be discarded if it is only informative when combined with another feature.\n",
    "\n",
    "Univariate tests are often very fast to compute, and don’t require building a model. \n",
    "\n",
    "On the other hand, they are completely independent of the model that you might want to apply after the feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods differ in how they select relevant features, with the simplest ones being `SelectKBest`, which selects a fixed number `k` of features, and `SelectPercentile`, which selects a fixed percentage of features.\n",
    "\n",
    "Here we will use `SelectPercentile` in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(SelectPercentile(percentile=50),\n",
    "                     KNeighborsClassifier(n_neighbors=17))\n",
    "        \n",
    "classification_results = general_classifier(madelon_feature_df,\n",
    "                                            madelon_target_df,\n",
    "                                            pipe,\n",
    "                                            42)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_results['train_score'], classification_results['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw this above using `SelectKBest`. Just as we did a grid search with `SelectKBest`, we could do a grid search with `SelectPercentile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = dict(selectpercentile__percentile=[40,45,50,55,60,65])\n",
    "pipe_grid_search = GridSearchCV(pipe, param_grid=params)\n",
    "grid_search_results = general_classifier(madelon_feature_df,\n",
    "                                         madelon_target_df,\n",
    "                                         pipe_grid_search,\n",
    "                                         42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_search_results['classifier'].cv_results_)\n",
    "results_df.head(3)\n",
    "fig = plt.figure(figsize=(20,4))\n",
    "\n",
    "fig.add_subplot(121)\n",
    "sns.stripplot(y='mean_train_score',\n",
    "              x='param_selectpercentile__percentile',\n",
    "              data=results_df)\n",
    "plt.ylim(0.6,1)\n",
    "\n",
    "fig.add_subplot(122)\n",
    "sns.stripplot(y='mean_test_score',\n",
    "              x='param_selectpercentile__percentile',\n",
    "              data=results_df)\n",
    "plt.ylim(0.6,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Support of our Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we were interested in which features were removed (in a context where the features have meaning!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_cls = grid_search_results['classifier']\n",
    "selector = gs_cls.estimator.steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = selector[1].get_support()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Sample index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Based Feature Selection\n",
    "\n",
    "Model-based feature selection uses a supervised machine learning model to judge the importance of each feature, and keeps only the most important ones.\n",
    "\n",
    "The supervised model that is used for feature selection doesn’t need to be the same model that is used for the final supervised modeling.\n",
    "\n",
    "The feature selection model needs to provide some measure of importance for each feature, so that they can be ranked by this measure.\n",
    "\n",
    "Decision trees and decision tree–based models provide a `feature_importances_` attribute, which directly encodes the importance of each feature.\n",
    "\n",
    "We will explore Decision Trees and their derivate models in depth later. For now, they are just another tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_cls = RandomForestClassifier(n_estimators=500, random_state=42) \n",
    "select = SelectFromModel(rf_cls, threshold=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(select,\n",
    "                     KNeighborsClassifier(n_neighbors=17))\n",
    "        \n",
    "classification_results = general_classifier(madelon_feature_df,\n",
    "                                            madelon_target_df,\n",
    "                                            pipe,\n",
    "                                            42)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_results['train_score'], classification_results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = dict(selectfrommodel__estimator=[\n",
    "        RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "        RandomForestClassifier(n_estimators=300, random_state=42),\n",
    "        RandomForestClassifier(n_estimators=400, random_state=42),\n",
    "        RandomForestClassifier(n_estimators=500, random_state=42),\n",
    "        RandomForestClassifier(n_estimators=600, random_state=42),\n",
    "    ])\n",
    "pipe_grid_search = GridSearchCV(pipe, param_grid=params)\n",
    "grid_search_results = general_classifier(madelon_feature_df,\n",
    "                                         madelon_target_df,\n",
    "                                         pipe_grid_search,\n",
    "                                         42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_search_results['classifier'].cv_results_)\n",
    "results_df.head(3)\n",
    "fig = plt.figure(figsize=(20,4))\n",
    "\n",
    "fig.add_subplot(121)\n",
    "strp_plt = sns.stripplot(y='mean_train_score', \n",
    "                         x='param_selectfrommodel__estimator',\n",
    "                         data=results_df)\n",
    "strp_plt.set(xticklabels=[100,200,300,400,500,600])\n",
    "plt.ylim(0.6,1)\n",
    "\n",
    "fig.add_subplot(122)\n",
    "strp_plt = sns.stripplot(y='mean_test_score', \n",
    "                         x='param_selectfrommodel__estimator',\n",
    "                         data=results_df)\n",
    "strp_plt.set(xticklabels=[100,200,300,400,500,600])\n",
    "plt.ylim(0.6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_cls = grid_search_results['classifier']\n",
    "selector = gs_cls.estimator.steps[0]\n",
    "mask = selector[1].get_support()\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Sample index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Feature Selection\n",
    "\n",
    "In univariate testing we used no model.\n",
    "\n",
    "In model-based selection we used a single model to select features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In iterative feature selection, a series of models are built, with varying numbers of features.\n",
    "\n",
    "There are two basic methods: starting with no features and adding features one by one until some stopping criterion is reached, or starting with all features and removing features one by one until some stopping criterion is reached.\n",
    "\n",
    "We have a lot of features, so we will set a fairly large step for this process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_cls = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "select = RFE(rf_cls, n_features_to_select=40, step=20)\n",
    "\n",
    "pipe = make_pipeline(select,\n",
    "                     KNeighborsClassifier(n_neighbors=17))\n",
    "        \n",
    "classification_results = general_classifier(madelon_feature_df,\n",
    "                                            madelon_target_df,\n",
    "                                            pipe,\n",
    "                                            42)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_results['train_score'], classification_results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_cls = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "select_1 = RFE(rf_cls, n_features_to_select=30, step=20)\n",
    "select_2 = RFE(rf_cls, step=1)\n",
    "\n",
    "pipe = make_pipeline(select_1, select_2, KNeighborsClassifier(n_neighbors=17))\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'rfe-2__n_features_to_select' : range(5,30)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_grid_search = GridSearchCV(pipe, param_grid=params)\n",
    "grid_search_results = general_classifier(madelon_feature_df,\n",
    "                                         madelon_target_df,\n",
    "                                         pipe_grid_search,\n",
    "                                         42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_search_results['classifier'].cv_results_)\n",
    "results_df.head(3)\n",
    "fig = plt.figure(figsize=(20,4))\n",
    "\n",
    "fig.add_subplot(121)\n",
    "strp_plt = sns.stripplot(y='mean_train_score', \n",
    "                         x='rfe-2__n_features_to_select',\n",
    "                         data=results_df)\n",
    "plt.ylim(0.6,1)\n",
    "\n",
    "fig.add_subplot(122)\n",
    "strp_plt = sns.stripplot(y='mean_test_score', \n",
    "                         x='rfe-2__n_features_to_select',\n",
    "                         data=results_df)\n",
    "plt.ylim(0.6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
