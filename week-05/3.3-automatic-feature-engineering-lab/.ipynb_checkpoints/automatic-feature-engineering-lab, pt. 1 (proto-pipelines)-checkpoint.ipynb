{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Thanks, Chris!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: './lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ff45fcc7214f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetcwd\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./lib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lib'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0miowa_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_iowa_liquor_store_dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: './lib'"
     ]
    }
   ],
   "source": [
    "from os import chdir, getcwd;\n",
    "chdir('../lib')\n",
    "assert getcwd().split('/')[-1] == 'lib'\n",
    "from iowa_data import load_iowa_liquor_store_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iowa_liquor_store_df, \\\n",
    "    iowa_liquor_store_deltas_df = \\\n",
    "        load_iowa_liquor_store_dataframes()\n",
    "\n",
    "iowa_liquor_store_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iowa_liquor_store_deltas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "For `iowa_liquor_store_df`\n",
    "1. Show the head, info and description\n",
    "1. Find the shape of the data\n",
    "1. Find the names of the columns\n",
    "\n",
    "For `iowa_liquor_store_deltas_df`\n",
    "1. Show the head, info and description\n",
    "1. Find the shape of the data\n",
    "1. Find the names of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "For `iowa_liquor_store_df`\n",
    "\n",
    "1. Plot a curve for a few zip codes showing sales per year  per\n",
    "1. Plot a curve for a few zip codes showing number of stores per year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Preprocessing\n",
    "\n",
    "Create a target vector using the `delta_2016Q4` column.\n",
    "Create a feature array by removing this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Standard Sklearn Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data\n",
    "1. Split the data into training and testing sets\n",
    "1. Create a new model\n",
    "1. Fit the model\n",
    "1. Score the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Cases: the Least Square Regressor and Standard Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `least_squares_regressor_standard_workflow`\n",
    "\n",
    "1. Pass the data as an argument\n",
    "1. Create the model inside the function. Use the `sklearn` implementation of OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_regressor_standard_workflow():\n",
    "    #TODO: Receive the data\n",
    "    #TODO: Split the data into training and testing sets; be sure to include an option to specify a random state\n",
    "    #TODO: Create a new OLS model \n",
    "    #TODO: Fit the model\n",
    "    #TODO: Score the model\n",
    "    #TODO: Return a dictionary containing the model, the train score, and the test score\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaler_standard_workflow():\n",
    "    #TODO: Load the data\n",
    "    #TODO: Split the data into training and testing sets\n",
    "    #TODO: Create a new scaler \n",
    "    #TODO: Fit the scaler\n",
    "    #TODO: transform the data\n",
    "    #TODO: return a dictionary containing the transformed data\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Your Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "least_squares_regressor_standard_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_standard_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Cases: A general regressor and a general transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `general_regressor_standard_workflow`\n",
    "\n",
    "This method should be able to receive data that has already been split. In order to handle this, you will need to\n",
    "\n",
    "1. Handle the case where one of `X_test` or `y_test` is missing\n",
    "1. Use `X` and `y` as the training data if testing data is received\n",
    "1. Perform the train test split if testing data is not received\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def general_regressor_standard_workflow(model, X, y, random_state=None, X_test=None, y_test=None):\n",
    "    #TODO: error handling if X_test is received by y_test is not and vice versa\n",
    "    #TODO: if testing data is received, assign X, y to X_train, Y_train\n",
    "    #TODO: if testing data is not received split the data into training and testing sets (with random state)\n",
    "    #TODO: Fit the model\n",
    "    #TODO: Score the model\n",
    "    #TODO: Return a dictionary containing the model, the train score, and the test score\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def general_transformer_standard_workflow(transformer, X, y, split_data=False, random_state=None, X_test=None, y_test=None):\n",
    "    #TODO: error handling if X_test is received by y_test is not and vice versa\n",
    "    #TODO: if testing data is received, assign X, y to X_train, Y_train\n",
    "    #TODO: if split_data is True,  split the data into training and testing sets (with random state)\n",
    "    #TODO: if X_train, y_train exist (either because it was assigned or because data was split) use X_train, y_train data to \n",
    "    #TODO:     Fit the model\n",
    "    #TODO: otherwise use X, y to \n",
    "    #TODO:     Fit the model\n",
    "    #TODO: Transform data as needed\n",
    "    #TODO: return a dictionary containing transformed data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Your Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling, then Fit-Score\n",
    "\n",
    "#### Use `general_transformer_standard_workflow` to\n",
    "\n",
    "1. split the data into training and testing sets\n",
    "1. scale your data using `Scaler`\n",
    "1. return the split-scaled data\n",
    "\n",
    "#### Pass the results of this and a new `Lasso` model that you created to `general_regressor_standard_workflow` and\n",
    "\n",
    "1. receive the split data\n",
    "1. fit the `Lasso` model\n",
    "1. score the `Lasso` model\n",
    "\n",
    "#### Examine the coefficients of the `Lasso` model and create a list of booleans representing whether or not a feature was used.\n",
    "\n",
    "Optionally, use the code below to represent which features were identified as \"salient\".\n",
    "\n",
    "    plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "    plt.xlabel(\"Sample index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Salient Features using ANOVA via `SelectKBest`\n",
    "\n",
    "#### Use `general_transformer_standard_workflow` to\n",
    "\n",
    "1. split the data into training and testing sets\n",
    "1. scale your data using `Scaler`\n",
    "1. return the split-scaled data\n",
    "\n",
    "#### Pass the results of this and a new `SelectKBest` model that you created to `general_transformer_standard_workflow` and\n",
    "\n",
    "1. receive the split data\n",
    "1. fit the `SelectKBest` model\n",
    "1. transform the data \n",
    "1. return the transformed data\n",
    "1. Use `.get_support()` to identify the salient features\n",
    "\n",
    "Compare the salient features identified by `SelectKBest` to the salient features identified by the `Lasso`. \n",
    "\n",
    "If you plotted the salient features for the `Lasso`, do the same for the features from `SelectKBest`.\n",
    "\n",
    "Tweak the `k` value of `SelectKBest` as you see fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit models using the Transformed Feature Set received from `SelectKBest`\n",
    "\n",
    "#### Pass the results of your `SelectKBest` and each of three different models (below) to `general_regressor_standard_workflow` and\n",
    "\n",
    "1. receive the split data\n",
    "1. fit the `Lasso` model\n",
    "1. score the `Lasso` model\n",
    "\n",
    "#### Use these models\n",
    "\n",
    "1. `Ridge`\n",
    "1. `LinearRegression`\n",
    "1. `SGDRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a Brief Write-Up of What you Found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
